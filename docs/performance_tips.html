---
layout: default
title: Performance Tips
description: Guidance for scaling InsideForest to large datasets.
nav_order: 5
---

<h1>Performance Tips</h1>
<p>InsideForest includes automated heuristics, but tuning a few parameters can significantly improve runtime and memory usage. Use the following guidelines when working with large datasets.</p>

<h2>Leverage auto presets</h2>
<ul>
  <li><strong><code>auto_fast=True</code>:</strong> enables internal shortcuts that reduce the number of evaluated regions and increases sampling efficiency.</li>
  <li><strong><code>auto_feature_reduce=True</code>:</strong> keeps only the most discriminative features per region, lowering dimensionality before clustering.</li>
  <li><strong><code>n_sample_multiplier</code> and <code>ef_sample_multiplier</code>:</strong> control how many samples feed the branch extraction step. Lower values decrease runtime but may miss rare patterns.</li>
</ul>

<h2>Control tree complexity</h2>
<ul>
  <li>Limit <code>max_depth</code> or <code>min_samples_leaf</code> in the underlying forest to avoid overly fragmented branches.</li>
  <li>Use <code>rf_params</code> to pass custom <code>RandomForest</code> settings such as <code>n_estimators</code>, <code>max_features</code>, or bootstrapping.</li>
  <li>Reuse an existing forest when you already have a calibrated model; this skips training time completely.</li>
</ul>

<h2>Batch predictions</h2>
<ul>
  <li>InsideForest estimators accept NumPy arrays, pandas DataFrames, and Spark DataFrames.</li>
  <li>For pandas inputs, prefer <code>predict</code> and <code>describe_clusters</code> in batches to avoid exhausting memory.</li>
  <li>Use <code>predict_proba</code> on classifiers only when probability calibration is required, as it introduces extra computations.</li>
</ul>

<h2>Monitor feature importance</h2>
<ul>
  <li>Inspect <code>feature_importances_</code> to spot features that dominate rules. Consider removing low-signal columns to simplify the search space.</li>
  <li>Combine <code>auto_feature_reduce</code> with domain knowledge to cap the maximum number of conditions per region.</li>
</ul>

<h2>Persist intermediate artifacts</h2>
<ul>
  <li>Call <code>save</code> on classifiers or regressors to store the forest, region cache, and metadata. Reload them with <code>load</code> to resume analysis.</li>
  <li>Export region descriptions to CSV or JSON using <code>generate_descriptions</code> for downstream dashboards.</li>
</ul>

<h2>Validate with experiments</h2>
<p>Use the recommendations in <a href="experiments_benchmarks.html">Experiments &amp; Benchmarks</a> to design reproducible evaluations before moving to production.</p>
