[
  {
    "title": "Rendimiento",
    "url": "performance_tips_es.html",
    "content": "Consejos de rendimiento Acelera tus experimentos con estas recomendaciones para datasets amplios o con muchas variables. Presets automáticos auto_fast=True ajusta la profundidad de los árboles y reduce el número de muestras analizadas. auto_feature_reduce=True selecciona automáticamente las variables más relevantes. Consulta _fast_params_used_ para registrar la configuración aplicada. Extracción de reglas Parámetro Rol Recomendación n_sample_multiplier Tamaño de muestra por árbol. Empieza en 0.05 y aumenta cuando requieras mayor granularidad. ef_sample_multiplier Muestreo para explorar ramas adicionales. Valores entre 5 y 15 equilibran tiempo y cobertura. max_depth Profundidad máxima del bosque. Limitarlo a 10-15 suele mejorar tiempos y evita reglas demasiado específicas. Selección de clústeres select_clusters: ideal para resultados rápidos. menu: explora candidatos adicionales cuando buscas máxima precisión. balance_lists_n_clusters: útil cuando necesitas clústeres de tamaño similar. Procesamiento por lotes Evalúa datos masivos en bloques y combina los resultados con predict. Guarda el progreso con .save() para reanudar entrenamientos costosos. Limita salidas visuales, por ejemplo plot_importances(max_features=20). Monitorea recursos Aprovecha Models y las utilidades de metadatos para registrar tiempos y memoria. Complementa con los casos de Experimentos y benchmarks y sigue las pautas de reproducibilidad.",
    "excerpt": "Consejos de rendimiento Acelera tus experimentos con estas recomendaciones para datasets amplios o con muchas variables. Presets automáticos auto_fast=True ajusta la profundidad de los árboles y reduce el número de muestras analizadas. auto…"
  },
  {
    "title": "Cómo Funciona",
    "url": "how_it_works_es.html",
    "content": "Cómo funciona InsideForest InsideForest parte de un bosque entrenado y lo transforma en regiones descriptivas. El flujo general sigue cuatro pasos: árboles → reglas → regiones → etiquetas. 1. Construye o reutiliza un bosque Entrena un RandomForest con scikit-learn o conecta un modelo de PySpark. Los envoltorios de InsideForest aceptan parámetros típicos, y la clase Trees permite extraer ramas explícitamente. from InsideForest import Trees trees = Trees(\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10) ramas = trees.get_branches(X, y, modelo) 2. Prioriza regiones candidatas Regions.prio_ranges fusiona reglas, calcula métricas y destaca aquellas con alta pureza y cobertura. from InsideForest import Regions regions = Regions() rangos = regions.prio_ranges(ramas, X) Si activas auto_feature_reduce, se eliminan variables con baja contribución antes de generar las regiones. 3. Etiqueta observaciones regions.labels asigna cada observación a una región y, con return_dfs=True, devuelve DataFrames descriptivos listos para análisis. df = X.copy() df[\"target\"] = y clusteres, descripciones, etiquetas = regions.labels( df=df, df_reres=rangos, n_clusters=None, include_summary_cluster=False, method=\"select_clusters\", return_dfs=True, var_obj=\"target\", ) Utiliza los auxiliares de InsideForest.cluster_selector como select_clusters, menu o match_class_distribution para controlar el balance entre clases. 4. Interpreta y comparte El módulo Labels produce métricas por segmento y Models ofrece utilidades para comparar modelos y exportar reglas. generate_descriptions redacta resúmenes ejecutivos. categorize_conditions agrupa restricciones por tipo. plot_multi_dims genera visualizaciones de 2D y 3D. Flujo completo from InsideForest import InsideForestClassifier clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True, method=\"menu\", get_detail=True) clf.fit(X_train, y_train) etiquetas = clf.predict(X_test) resumenes = clf.df_clusters_description_ Más recursos Rendimiento para ajustar hiperparámetros. Experimentos y benchmarks para resultados cuantitativos. Reproducibilidad para garantizar experimentos repetibles.",
    "excerpt": "Cómo funciona InsideForest InsideForest parte de un bosque entrenado y lo transforma en regiones descriptivas. El flujo general sigue cuatro pasos: árboles → reglas → regiones → etiquetas. 1. Construye o reutiliza un bosque Entrena un Rando…"
  },
  {
    "title": "API Rápida",
    "url": "quick_api_es.html",
    "content": "API Rápida Esta guía resume los patrones esenciales de uso de InsideForest para clasificación y regresión. Las clases mantienen la convención fit/predict de scikit-learn. Flujo para clasificación from sklearn.datasets import load_iris from InsideForest import InsideForestClassifier X, y = load_iris(return_X_y=True) clf = InsideForestClassifier( rf_params={\"n_estimators\": 400, \"random_state\": 21}, auto_fast=True, get_detail=True, ) clf.fit(X, y) labels = clf.predict(X) resumen = clf.df_clusters_description_ Activa get_detail=True para conservar las tablas generadas durante el ajuste. Explora clf.feature_importances_, clf.plot_importances() y clf.df_datos_explain_ para comunicar qué variables generan cada segmento. Los registros que no cumplen ninguna regla reciben la etiqueta -1; revisa la advertencia emitida por predict para cuantificarlos. Flujo para regresión from sklearn.datasets import load_diabetes from InsideForest import InsideForestRegressor X, y = load_diabetes(return_X_y=True) regr = InsideForestRegressor(auto_feature_reduce=True, get_detail=True) regr.fit(X, y) pred = regr.predict(X) reglas = regr.df_clusters_description_ El parámetro auto_feature_reduce elimina variables poco informativas antes de generar las regiones. Con get_detail=True obtienes df_clusters_description_ y df_datos_explain_ para análisis adicionales. Estrategias de selección de clústeres from InsideForest import cluster_selector menu = cluster_selector.MenuClusterSelector(quota=0.2) menu.fit(clf.df_reres_, y) ajustado = menu.predict(clf.df_reres_) \"select_clusters\": selección directa basada en reglas. cluster_selector.balance_lists_n_clusters: reparte observaciones de forma uniforme. cluster_selector.max_prob_clusters: prioriza segmentos con probabilidad alta. cluster_selector.match_class_distribution y MenuClusterSelector: preservan proporciones entre clases. Persistencia de modelos clf.save(\"modelo.joblib\") cargado = InsideForestClassifier.load(\"modelo.joblib\") assert cargado._fast_params_used_ == clf._fast_params_used_ La carga restaura tanto el bosque entrenado como las regiones calculadas, permitiendo continuar con predicciones y análisis. ¿Qué sigue? Lee Cómo funciona para profundizar en árboles, regiones y etiquetas. Visita la referencia completa para conocer cada módulo disponible. Antes de ejecutar experimentos intensivos, revisa consejos de rendimiento.",
    "excerpt": "API Rápida Esta guía resume los patrones esenciales de uso de InsideForest para clasificación y regresión. Las clases mantienen la convención fit/predict de scikit-learn. Flujo para clasificación from sklearn.datasets import load_iris from …"
  },
  {
    "title": "Experimentos y Benchmarks",
    "url": "experiments_benchmarks_es.html",
    "content": "Experimentos y benchmarks Los siguientes resultados sirven como referencia para evaluar InsideForest en distintas tareas. Cada experimento incluye un conjunto de datos público y métricas reproducibles. Datasets evaluados Dataset Tarea Observaciones Variables Métrica UCI Adult Clasificación 48 842 14 F1 macro = 0.86 Credit Default Clasificación 30 000 23 AUC = 0.82 Boston Housing Regresión 506 13 RMSE = 3.1 Metodología División estratificada 35% entrenamiento / 65% evaluación. Presets auto_fast y auto_feature_reduce habilitados por defecto. Semilla fija (random_state=15) para permitir comparaciones directas. Baselines con RandomForest y KMeans para medir ganancias. Hallazgos Interpretabilidad: las reglas finales contienen en promedio menos de cinco condiciones. Balance: el método menu mitiga la dominancia de clases mayoritarias. Tiempo: cada corrida se completa en menos de ocho minutos en CPU moderna. Cómo replicar cd experiments python adult_experiment.py --auto-fast --save-report python credit_default.py --compare-baselines Para más detalles revisa Reproducibilidad y ajusta parámetros con Rendimiento.",
    "excerpt": "Experimentos y benchmarks Los siguientes resultados sirven como referencia para evaluar InsideForest en distintas tareas. Cada experimento incluye un conjunto de datos público y métricas reproducibles. Datasets evaluados Dataset Tarea Obser…"
  },
  {
    "title": "Reproducibility",
    "url": "reproducibility.html",
    "content": "Reproducibility InsideForest relies on randomness during tree training and region sampling. Follow these guidelines to produce repeatable experiments. Fix random seeds Set random_state in the underlying forest via rf_params. When using NumPy or pandas pipelines, seed them explicitly: np.random.seed(42). Use PYTHONHASHSEED=0 when running scripts to keep hashing consistent. Log environment details Capture the output of pip freeze or conda env export in each experiment folder. Document the dataset version, preprocessing steps, and any filtering applied before training. Record hardware characteristics (CPU cores, RAM) when benchmarking performance. Persist models and metadata Use save / load methods from classifiers or regressors to archive fitted models. Store df_clusters_description_, df_datos_explain_, and generate_descriptions outputs alongside evaluation metrics. Use version control (Git) to track notebooks and configuration files. Automate checks Create smoke tests that run fit and predict on a reduced dataset. Include assertions for metric thresholds to catch regressions early. Schedule periodic runs with tools such as GitHub Actions to validate dependencies. Share results Combine these practices with the logging templates from Experiments & Benchmarks so collaborators can reproduce findings with minimal setup.",
    "excerpt": "Reproducibility InsideForest relies on randomness during tree training and region sampling. Follow these guidelines to produce repeatable experiments. Fix random seeds Set random_state in the underlying forest via rf_params. When using NumP…"
  },
  {
    "title": "Instalación",
    "url": "installation_es.html",
    "content": "Instalación InsideForest está disponible en PyPI y también puede instalarse desde el repositorio para contribuir con nuevas funciones. Se recomienda trabajar dentro de un entorno virtual. Requisitos previos Python 3.9 o superior. pip actualizado (python -m pip install --upgrade pip). Herramientas de compilación para dependencias científicas cuando sea necesario. Instalación desde PyPI pip install insideforest Valida que la importación funcione: python -c \"from InsideForest import InsideForestClassifier; print('InsideForest listo')\" Instalación desde el código fuente git clone https://github.com/jcval94/InsideForest.git cd InsideForest pip install -e . El modo editable permite iterar sobre el código sin reinstalar el paquete en cada cambio. Dependencias para desarrollo pip install -e .[dev] # o pip install -r requirements-dev.txt Incluyen linters, herramientas de documentación y dependencias de pruebas. Comprueba la instalación PYTHONPATH=src pytest tests/test_basic.py::test_import_and_fit -q Esta prueba realiza un entrenamiento mínimo para asegurarse de que la configuración está completa. Resolución de problemas Compilación: instala paquetes de compilación (por ejemplo, build-essential o xcode-select --install). Dependencias: crea un entorno con python -m venv .venv o conda create -n insideforest python=3.11. Entornos corporativos: si el proxy bloquea PyPI, descarga los paquetes y usa pip install *.whl. Después de instalar, continúa con API Rápida para ejecutar tu primer pipeline.",
    "excerpt": "Instalación InsideForest está disponible en PyPI y también puede instalarse desde el repositorio para contribuir con nuevas funciones. Se recomienda trabajar dentro de un entorno virtual. Requisitos previos Python 3.9 o superior. pip actual…"
  },
  {
    "title": "Roadmap",
    "url": "roadmap.html",
    "content": "Roadmap The roadmap outlines upcoming improvements. Priorities may change as new feedback arrives. In progress Improved Spark support: streamline the interface for PySpark DataFrames and add automated schema validation. Interactive dashboards: publish Streamlit templates to explore clusters and export rule summaries. Planned Model explainers: integrate SHAP-style visualizations tailored to InsideForest regions. Time-series helpers: add utilities to segment temporal data with sliding windows. Rust backend prototype: experiment with a compiled implementation to reduce inference latency. Community requests Share ideas or vote on priorities via GitHub issues. Tag proposals with roadmap and describe the use case, dataset size, and desired outcome. Recently delivered Language toggle across the documentation site. Expanded API reference with cross-links between modules. New reproducibility guidelines covering seeding, logging, and automation.",
    "excerpt": "Roadmap The roadmap outlines upcoming improvements. Priorities may change as new feedback arrives. In progress Improved Spark support: streamline the interface for PySpark DataFrames and add automated schema validation. Interactive dashboar…"
  },
  {
    "title": "Licencia",
    "url": "license_es.html",
    "content": "Licencia InsideForest se distribuye bajo la licencia MIT. Puedes usar, modificar y redistribuir el software siempre que incluyas el aviso de copyright y esta nota de permiso. Licencia MIT Copyright (c) {{ site.time | date: '%Y' }} José Carlos Del Valle Se concede permiso, libre de cargos, a cualquier persona que obtenga una copia de este software y de los archivos de documentación asociados (el \"Software\"), para utilizar el Software sin restricción, incluyendo sin limitación los derechos a usar, copiar, modificar, fusionar, publicar, distribuir, sublicenciar y/o vender copias del Software, y a permitir a las personas a las que se les proporcione el Software que lo hagan, sujeto a las siguientes condiciones: El aviso de copyright anterior y este aviso de permiso deberán incluirse en cualquier copia o parte sustancial del Software. EL SOFTWARE SE PROPORCIONA \"TAL CUAL\", SIN GARANTÍA DE NINGÚN TIPO, EXPRESA O IMPLÍCITA, INCLUYENDO PERO NO LIMITADO A GARANTÍAS DE COMERCIALIZACIÓN, ADECUACIÓN A UN PROPÓSITO PARTICULAR E INCUMPLIMIENTO. EN NINGÚN CASO LOS AUTORES O TITULARES DEL COPYRIGHT SERÁN RESPONSABLES DE NINGUNA RECLAMACIÓN, DAÑO U OTRA RESPONSABILIDAD, YA SEA EN UNA ACCIÓN CONTRACTUAL, AGRAVIO O DE OTRO TIPO, QUE SURJA DE, FUERA DE O EN CONEXIÓN CON EL SOFTWARE O SU USO U OTRAS OPERACIONES EN EL SOFTWARE. Consulta el archivo LICENSE del repositorio para el texto completo.",
    "excerpt": "Licencia InsideForest se distribuye bajo la licencia MIT. Puedes usar, modificar y redistribuir el software siempre que incluyas el aviso de copyright y esta nota de permiso. Licencia MIT Copyright (c) {{ site.time | date: '%Y' }} José Carl…"
  },
  {
    "title": "Experiments & Benchmarks",
    "url": "experiments_benchmarks.html",
    "content": "Experiments & Benchmarks Use these guidelines to evaluate InsideForest consistently across datasets. The examples below summarize public experiments performed on open datasets. Methodology checklist Split data with stratified sampling to preserve class balance. Compare InsideForest against standard baselines such as RandomForestClassifier or GradientBoostingClassifier. Repeat experiments with at least five different seeds and report the mean ± standard deviation. Track both predictive metrics (accuracy, F1, RMSE) and interpretability metrics (number of rules, coverage, purity). Sample classification results Dataset Metric InsideForest Baseline Notes Iris Accuracy 0.964 ± 0.01 0.953 ± 0.02 (RandomForest) InsideForest produced 6 descriptive rules covering 100% of samples. Wine Quality F1 weighted 0.732 ± 0.03 0.701 ± 0.04 (GradientBoosting) Feature reduction kept 9 of 12 variables with no drop in accuracy. Sample regression results Dataset Metric InsideForest Baseline Notes California Housing RMSE 0.48 ± 0.02 0.51 ± 0.02 (RandomForest) Auto feature reduction reduced runtime by 18%. Energy Efficiency RMSE 0.36 ± 0.01 0.39 ± 0.01 (XGBoost) InsideForest produced 8 rules with coverage above 90%. Reporting template When documenting new experiments, include: Dataset description and preprocessing steps. Parameter grid with ranges for each model. Evaluation scripts or notebook links. Raw outputs (metrics, confusion matrices, rule exports). Reproducing published results Clone the repository and explore the experiments/ directory. Notebooks contain ready-to-run configurations that mirror the tables above.",
    "excerpt": "Experiments & Benchmarks Use these guidelines to evaluate InsideForest consistently across datasets. The examples below summarize public experiments performed on open datasets. Methodology checklist Split data with stratified sampling to pr…"
  },
  {
    "title": "License",
    "url": "license.html",
    "content": "License InsideForest is released under the MIT License. You are free to use, modify, and distribute the software, provided that the copyright notice and permission notice appear in all copies. MIT License Copyright (c) {{ site.time | date: '%Y' }} José Carlos Del Valle Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. See the LICENSE file in the repository for the authoritative text.",
    "excerpt": "License InsideForest is released under the MIT License. You are free to use, modify, and distribute the software, provided that the copyright notice and permission notice appear in all copies. MIT License Copyright (c) {{ site.time | date: …"
  },
  {
    "title": "Preguntas frecuentes",
    "url": "faq_es.html",
    "content": "Preguntas frecuentes ¿InsideForest sustituye a un clasificador? No. InsideForest parte de un modelo existente y lo convierte en segmentos explicables. Continúa usando tu modelo principal para producción. ¿Necesito etiquetas? Sí. La técnica es supervisada; requiere etiquetas para guiar la búsqueda de regiones. ¿Funciona con PySpark? Sí. Emplea Trees('pyspark') para extraer reglas de un RandomForestClassifier entrenado en Spark. ¿Cómo comunico los resultados? Tras ajustar con get_detail=True revisa df_clusters_description_ y df_datos_explain_ para obtener tablas claras. Complementa con generate_descriptions cuando necesites textos automáticos. ¿Qué tamaño de datos soporta? Se ha probado con millones de registros en CPU. Activa auto_fast y revisa consejos de rendimiento para mejorar tiempos. ¿Dónde reporto problemas? Abre un issue con detalles del entorno, versión y pasos mínimos de reproducción. Adjunta pip freeze y resultados de pytest -q. ¿Dónde hay ejemplos completos? Revisa los notebooks en experiments/, los tutoriales y la documentación del README. Si tu pregunta no aparece aquí, sugiere nuevos temas en la hoja de ruta.",
    "excerpt": "Preguntas frecuentes ¿InsideForest sustituye a un clasificador? No. InsideForest parte de un modelo existente y lo convierte en segmentos explicables. Continúa usando tu modelo principal para producción. ¿Necesito etiquetas? Sí. La técnica …"
  },
  {
    "title": "Registro de cambios",
    "url": "changelog_es.html",
    "content": "Registro de cambios Resumen de versiones y entregables destacados. Consulta el repositorio para un detalle línea por línea. 0.6.0 — En progreso Actualización de la documentación con navegación bilingüe y botones de copiado. Nuevas páginas de rendimiento, reproducibilidad y benchmarks. Optimización de df_clusters_description_ con métricas adicionales. 0.5.1 — 12 oct 2023 Ajustes en presets automáticos para clases desbalanceadas. Soporte para exportar modelos comprimidos. 0.5.0 — 3 ago 2023 Lanzamiento de InsideForestRegressor. Mejoras en reportes de interpretación del módulo Labels. Compatibilidad con PySpark para extraer reglas. 0.4.0 — 18 abr 2023 Nuevos auxiliares de selección con estrategias configurables. Automatización de reducción de características. Para conocer planes futuros visita la hoja de ruta y consulta reproducibilidad si necesitas replicar versiones previas.",
    "excerpt": "Registro de cambios Resumen de versiones y entregables destacados. Consulta el repositorio para un detalle línea por línea. 0.6.0 — En progreso Actualización de la documentación con navegación bilingüe y botones de copiado. Nuevas páginas d…"
  },
  {
    "title": "Quick API",
    "url": "quick_api.html",
    "content": "Quick API This reference summarizes the basic flows to train, evaluate, and persist InsideForest models. All classes follow an interface similar to scikit-learn. Classifier workflow from sklearn.datasets import load_iris from InsideForest import InsideForestClassifier X, y = load_iris(return_X_y=True) clf = InsideForestClassifier( rf_params={\"n_estimators\": 400, \"random_state\": 21}, auto_fast=True, get_detail=True, ) clf.fit(X, y) cluster_labels = clf.predict(X) rules = clf.df_clusters_description_ Tips: Set get_detail=True to persist the rule tables generated during fit. The df_clusters_description_ attribute stores readable bounds and metrics per cluster. Use auto_fast=True to apply performance presets automatically and inspect _fast_params_used_ for the applied overrides. Records that do not match any learned rule receive the label -1; review the warning emitted during predict to quantify them. Regressor workflow from sklearn.datasets import load_diabetes from InsideForest import InsideForestRegressor X, y = load_diabetes(return_X_y=True) regr = InsideForestRegressor(auto_feature_reduce=True, get_detail=True) regr.fit(X, y) predictions = regr.predict(X) region_rules = regr.df_clusters_description_ Enable auto_feature_reduce to limit the number of variables that participate in clustering. When get_detail=True, descriptive DataFrames are exposed via df_clusters_description_ and df_datos_explain_. Cluster selection strategies Control how clusters are consolidated by setting the method parameter or using the helpers in InsideForest.cluster_selector: from InsideForest import cluster_selector menu = cluster_selector.MenuClusterSelector(quota=0.2) menu.fit(clf.df_reres_, y) rebalanced = menu.predict(clf.df_reres_) \"select_clusters\" (default) applies direct rules. cluster_selector.balance_lists_n_clusters and cluster_selector.match_class_distribution rebalance assignments. cluster_selector.max_prob_clusters favors segments with higher probabilities. MenuClusterSelector maximizes information when multiple candidates exist. Model persistence clf.save(\"model.joblib\") loaded = InsideForestClassifier.load(\"model.joblib\") assert list(loaded.feature_names_out_) == list(clf.feature_names_out_) Serialized models include the base forest, computed rules, and metadata so you can continue the analysis later. Next steps Go deeper in How It Works to understand the full pipeline. Explore the API reference to review every module. Visit Performance Tips when working with large datasets.",
    "excerpt": "Quick API This reference summarizes the basic flows to train, evaluate, and persist InsideForest models. All classes follow an interface similar to scikit-learn. Classifier workflow from sklearn.datasets import load_iris from InsideForest i…"
  },
  {
    "title": "How It Works",
    "url": "how_it_works.html",
    "content": "How InsideForest Works InsideForest takes a trained decision forest and turns it into interpretable regions. The full pipeline follows four stages: trees → rules → regions → labels. 1. Build or reuse a forest You can train a RandomForest directly or provide a pre-trained forest from PySpark. The InsideForestClassifier and InsideForestRegressor wrappers accept common scikit-learn parameters, or you can use the Trees class to extract branches manually. from InsideForest import Trees trees = Trees(\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10) branches = trees.get_branches(X, y, fitted_model) 2. Prioritize candidate regions Regions.prio_ranges combines the rules from every tree, computes coverage metrics, and highlights regions that balance purity and size. from InsideForest import Regions regions = Regions() priority_ranges = regions.prio_ranges(branches, X) This stage can also reduce features when auto_feature_reduce=True, keeping only the most discriminative variables. 3. Label observations The prioritized regions are used to label new or existing observations. The regions.labels function assigns rules, calculates metrics, and—when return_dfs=True—returns detailed DataFrames. df = X.copy() df[\"target\"] = y clustered, descriptive, labels = regions.labels( df=df, df_reres=priority_ranges, n_clusters=None, include_summary_cluster=False, method=\"select_clusters\", return_dfs=True, var_obj=\"target\", ) Labels can be consolidated with strategies such as select_clusters, menu, or match_class_distribution using the helpers from InsideForest.cluster_selector. 4. Interpret and export The Labels module summarizes metrics per cluster, while Models offers tools to compare baselines and export rules. generate_descriptions produces short narratives for analysts. categorize_conditions groups rules by constraint type. plot_multi_dims visualizes regions in 2D or 3D. Putting it together The snippet below illustrates the full flow using the high-level wrappers: from InsideForest import InsideForestClassifier clf = InsideForestClassifier( auto_fast=True, auto_feature_reduce=True, method=\"menu\", get_detail=True, ) clf.fit(X_train, y_train) labels = clf.predict(X_test) descriptions = clf.df_clusters_description_ Learn more Performance Tips to fine-tune parameters. Experiments & Benchmarks to review quantitative results. Reproducibility to guarantee reliable experiments.",
    "excerpt": "How InsideForest Works InsideForest takes a trained decision forest and turns it into interpretable regions. The full pipeline follows four stages: trees → rules → regions → labels. 1. Build or reuse a forest You can train a RandomForest di…"
  },
  {
    "title": "Performance Tips",
    "url": "performance_tips.html",
    "content": "Performance Tips InsideForest includes automated heuristics, but tuning a few parameters can significantly improve runtime and memory usage. Use the following guidelines when working with large datasets. Leverage auto presets auto_fast=True: enables internal shortcuts that reduce the number of evaluated regions and increases sampling efficiency. auto_feature_reduce=True: keeps only the most discriminative features per region, lowering dimensionality before clustering. n_sample_multiplier and ef_sample_multiplier: control how many samples feed the branch extraction step. Lower values decrease runtime but may miss rare patterns. Control tree complexity Limit max_depth or min_samples_leaf in the underlying forest to avoid overly fragmented branches. Use rf_params to pass custom RandomForest settings such as n_estimators, max_features, or bootstrapping. Reuse an existing forest when you already have a calibrated model; this skips training time completely. Batch predictions InsideForest estimators accept NumPy arrays, pandas DataFrames, and Spark DataFrames. For pandas inputs, prefer predict and attribute access (df_clusters_description_) in batches to avoid exhausting memory. Use predict_proba on classifiers only when probability calibration is required, as it introduces extra computations. Monitor feature importance Inspect feature_importances_ to spot features that dominate rules. Consider removing low-signal columns to simplify the search space. Combine auto_feature_reduce with domain knowledge to cap the maximum number of conditions per region. Persist intermediate artifacts Call save on classifiers or regressors to store the forest, region cache, and metadata. Reload them with load to resume analysis. Export region descriptions to CSV or JSON using generate_descriptions for downstream dashboards. Validate with experiments Use the recommendations in Experiments & Benchmarks to design reproducible evaluations before moving to production.",
    "excerpt": "Performance Tips InsideForest includes automated heuristics, but tuning a few parameters can significantly improve runtime and memory usage. Use the following guidelines when working with large datasets. Leverage auto presets auto_fast=True…"
  },
  {
    "title": "FAQ",
    "url": "faq.html",
    "content": "Frequently Asked Questions Does InsideForest replace my production model? No. InsideForest starts from an already trained forest and transforms it into interpretable segments. Use it alongside production models to explain predictions. Do I need labeled data? Yes. InsideForest performs supervised clustering: it requires labels to guide the region search. Labels may come from experts, historical decisions, or other models. Can it work with PySpark? Yes. Use Trees('pyspark') to extract branches from a Spark RandomForestClassifier and continue with Regions and Labels just like in scikit-learn. How do I interpret the rules? After fitting with get_detail=True, inspect df_clusters_description_ and df_datos_explain_ for readable conditions (for example, age > 30 and income < 50K). Complement them with generate_descriptions when you need narrative summaries. How large can my dataset be? InsideForest has been tested with millions of rows on CPU. Enable auto_fast and follow Performance Tips to optimize resources. How do I report issues? Open a GitHub issue describing the environment (version, operating system, reproduction steps). Include pip freeze output and the result of pytest -q. Where can I find full examples? Explore the notebooks in the experiments/ directory and the published tutorials. You can also review the repository README. Have another question? Join the discussion in the repository issues and contribute to the roadmap.",
    "excerpt": "Frequently Asked Questions Does InsideForest replace my production model? No. InsideForest starts from an already trained forest and transforms it into interpretable segments. Use it alongside production models to explain predictions. Do I …"
  },
  {
    "title": "Changelog",
    "url": "changelog.html",
    "content": "Changelog This log highlights notable updates. Dates reference repository tags. v0.6.0 — 2024-02-15 Added language selector and refreshed documentation layout. Expanded API reference with dedicated pages per module. Introduced automated performance presets via auto_fast. v0.5.2 — 2023-11-03 Refined cluster selector helpers for class balancing. Documented df_clusters_description_ outputs for regressors. Optimized branch extraction to reduce memory usage by 12%. v0.5.0 — 2023-08-22 Released InsideForestRegressor with parity to the classifier interface. Implemented metadata export helpers for rule auditing. Published reproducibility and benchmarking guides. v0.4.1 — 2023-05-10 Stabilized PySpark integration and added DataFrame validation. Improved documentation for persistence workflows. v0.4.0 — 2023-03-18 First public release of InsideForestClassifier. Provided tutorials covering classification, regression, and pipelines.",
    "excerpt": "Changelog This log highlights notable updates. Dates reference repository tags. v0.6.0 — 2024-02-15 Added language selector and refreshed documentation layout. Expanded API reference with dedicated pages per module. Introduced automated per…"
  },
  {
    "title": "Installation",
    "url": "installation.html",
    "content": "Installation InsideForest is published on PyPI and can also be installed from source for development. Use an isolated environment to keep dependencies controlled. Prerequisites Python 3.9 or newer. An up-to-date pip: python -m pip install --upgrade pip. C/C++ build tools (for example, build-essential on Linux) in case scikit-learn needs compilation. Install from PyPI The quickest way to get started is to install the published package: pip install insideforest Verify that the package imports correctly: python -c \"from InsideForest import InsideForestClassifier; print('InsideForest ready')\" Install from source Clone the repository to access notebooks, experiments, and extra examples. git clone https://github.com/jcval94/InsideForest.git cd InsideForest pip install -e . The editable mode (-e) lets you modify the code and test changes without reinstalling. Development extras Install optional dependencies to run automated tests and reproducible notebooks: pip install -e .[dev] # or use the dedicated file pip install -r requirements-dev.txt Verify your setup Confirm that InsideForest works by running a basic test: PYTHONPATH=src pytest tests/test_basic.py::test_import_and_fit -q This command trains a small model to check that dependencies are configured properly. Troubleshooting Build errors: ensure the compiler toolchain is installed and that numpy and scikit-learn versions match the requirements. Dependency conflicts: create an isolated environment with python -m venv .venv or conda create -n insideforest python=3.11. GPU not required: InsideForest runs on CPU, so no special accelerators are needed. Continue with the Quick API to run your first supervised clustering workflow.",
    "excerpt": "Installation InsideForest is published on PyPI and can also be installed from source for development. Use an isolated environment to keep dependencies controlled. Prerequisites Python 3.9 or newer. An up-to-date pip: python -m pip install -…"
  },
  {
    "title": "InsideForest",
    "url": "index.html",
    "content": "InsideForest InsideForest turns decision forests into region explorers. The library performs supervised clustering to uncover label-guided segments and explain them with concise rules. Deploy InsideForest to surface meaningful regions without relying on manual feature engineering. Explore how supervised clustering reveals patterns that traditional tree ensembles hide. Try it in a notebook Train a classifier, label new observations, and retrieve feature importance scores in just a few lines. from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from InsideForest import InsideForestClassifier X, y = load_iris(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.35, stratify=y, random_state=15 ) clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True) clf.fit(X_train, y_train) labels = clf.predict(X_test) importances = clf.feature_importances_ Head to the Quick API to see additional classification and regression flows. What makes InsideForest different? Guided segmentation: combines the predictive power of random forests with heuristics that prioritize high-value regions. Interpretable descriptions: generates rule sets with clear limits for each cluster. Flexible integration: works with scikit-learn, PySpark, and custom forest backends. Analysis-ready toolkit: includes metrics, visualizations, and export helpers for production workflows. Start here Use these core resources to build your workflow: Installation: steps for installing from PyPI or from source. How It Works: walk through trees, regions, and labels. Performance Tips: tune parameters for large datasets. Reproducibility: fix seeds and track versions to repeat results. Explore the API surface Each component ships with detailed documentation: InsideForestClassifier and InsideForestRegressor — high-level wrappers. Trees, Regions, and Labels — extraction, prioritization, and labeling. Models and Metadata helpers — utilities for diagnostics and persistence. Cluster selector helpers — utilities to rebalance and consolidate segments. Guides & tutorials Dig into real scenarios and best practices: Architecture: understand how internal modules connect. Configuration: customize automatic parameters. Interpretation: share results with business teams. Tutorials: step-by-step notebooks for common tasks. Stay up to date Check the Changelog, explore the Roadmap, and resolve questions in the FAQ. If you want to contribute, follow the recommendations in Reproducibility and share your improvements on GitHub. Community & credits InsideForest is developed by José Carlos Del Valle. Connect on LinkedIn or explore his portfolio. Have ideas? Add them to the Roadmap.",
    "excerpt": "InsideForest InsideForest turns decision forests into region explorers. The library performs supervised clustering to uncover label-guided segments and explain them with concise rules. Deploy InsideForest to surface meaningful regions witho…"
  },
  {
    "title": "Reproducibilidad",
    "url": "reproducibility_es.html",
    "content": "Reproducibilidad Garantiza que otros puedan replicar tus resultados controlando semillas, dependencias y artefactos. Semillas consistentes import random import numpy as np from InsideForest import InsideForestClassifier SEMILLA = 15 random.seed(SEMILLA) np.random.seed(SEMILLA) modelo = InsideForestClassifier(random_state=SEMILLA) En PySpark, configura las semillas de cada estimador y limita particiones aleatorias para evitar variaciones. Versiona dependencias Incluye requirements-lock.txt generado con pip freeze. Documenta la versión exacta de InsideForest y scikit-learn. Registra _fast_params_used_ y _feature_mask_ cuando utilices presets automáticos. Guarda artefactos Persistir modelos con .save() y adjuntar los archivos .joblib. Archivar df_clusters_description_, df_datos_explain_, tablas y gráficos. Publicar scripts en experiments/ para facilitar su ejecución en CI/CD. Pruebas automatizadas PYTHONPATH=src pytest tests/test_basic.py::test_import_and_fit -q pytest tests/test_fast_presets.py -q Integra estas pruebas en tu pipeline y conserva los registros como evidencia. Complementa con los apartados de experimentos, rendimiento y el registro de cambios para documentar decisiones.",
    "excerpt": "Reproducibilidad Garantiza que otros puedan replicar tus resultados controlando semillas, dependencias y artefactos. Semillas consistentes import random import numpy as np from InsideForest import InsideForestClassifier SEMILLA = 15 random.…"
  },
  {
    "title": "InsideForest",
    "url": "index_es.html",
    "content": "InsideForest InsideForest transforma los bosques aleatorios en exploradores de regiones. El clustering supervisado guía la segmentación y produce descripciones basadas en reglas fáciles de comunicar. InsideForest permite descubrir regiones valiosas sin depender de ingeniería manual de características. Aprovecha el clúster supervisado para revelar patrones que los bosques tradicionales no muestran. Pruébalo en un notebook Entrena un clasificador, etiqueta nuevas observaciones y obtén importancias de variables en cuestión de minutos. from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from InsideForest import InsideForestClassifier X, y = load_iris(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.35, stratify=y, random_state=15 ) clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True) clf.fit(X_train, y_train) labels = clf.predict(X_test) importances = clf.feature_importances_ Visita API Rápida para más ejemplos de clasificación y regresión. ¿Por qué InsideForest? Segmentación guiada: combina bosques aleatorios con heurísticas que priorizan regiones de alto valor. Interpretabilidad: genera reglas con límites claros que describen cada clúster. Integración flexible: compatible con scikit-learn, PySpark y bosques personalizados. Análisis listo para producción: métricas, visualizaciones y exportaciones listas para compartir. Primeros pasos Utiliza estos recursos para construir tu flujo de trabajo: Instalación: instrucciones para PyPI y modo desarrollo. Cómo funciona: guía por árboles, regiones y etiquetas. Rendimiento: optimiza parámetros en conjuntos de datos grandes. Reproducibilidad: controla semillas y versiones para repetir resultados. Explora la API Consulta la documentación detallada de cada módulo: InsideForestClassifier y InsideForestRegressor. Trees, Regions y Labels. Models y utilidades de metadatos. Auxiliares de selección y estrategias de consolidación. Guías y tutoriales Aprende con casos reales y recomendaciones prácticas: Arquitectura: estructura interna del proyecto. Configuración: personaliza parámetros automáticos. Interpretación: comunica hallazgos a equipos de negocio. Tutoriales: recorridos paso a paso. Actualizaciones Consulta el registro de cambios, conoce la hoja de ruta y aclara dudas en las preguntas frecuentes. Antes de contribuir, revisa las recomendaciones de reproducibilidad. Comunidad InsideForest es desarrollado por José Carlos Del Valle. Conecta en LinkedIn o visita su portafolio. Comparte ideas y necesidades en la hoja de ruta.",
    "excerpt": "InsideForest InsideForest transforma los bosques aleatorios en exploradores de regiones. El clustering supervisado guía la segmentación y produce descripciones basadas en reglas fáciles de comunicar. InsideForest permite descubrir regiones …"
  },
  {
    "title": "Hoja de Ruta",
    "url": "roadmap_es.html",
    "content": "Hoja de ruta Estas iniciativas representan el rumbo actual de InsideForest. Participa enviando comentarios o creando issues con tus necesidades. En progreso Servicio REST opcional: publicar predicciones y reglas con un despliegue ligero. Visualizaciones enriquecidas: nuevas plantillas interactivas para plot_multi_dims. Documentación por industria: casos guiados para retail, banca y salud. Planeado Compatibilidad con modelos basados en lightgbm. Integración con feature stores y orquestadores de datos. Soporte nativo para problemas multi-etiqueta. Ideas en análisis Panel web para explorar regiones sin código. Conectores directos a fuentes SQL y BigQuery. Colección de recetas enfocadas en marketing y gestión de riesgo. Consulta el registro de cambios para ver entregables recientes y los benchmarks asociados.",
    "excerpt": "Hoja de ruta Estas iniciativas representan el rumbo actual de InsideForest. Participa enviando comentarios o creando issues con tus necesidades. En progreso Servicio REST opcional: publicar predicciones y reglas con un despliegue ligero. Vi…"
  },
  {
    "title": "Regression",
    "url": "tutorials/regression.html",
    "content": "Regression tutorial Model continuous values with InsideForest and explain each resulting region. Goal Predict diabetes progression using the classic Diabetes dataset included in scikit-learn. Step 1: load data from sklearn.datasets import load_diabetes X, y = load_diabetes(return_X_y=True) Step 2: train the regressor from InsideForest import InsideForestRegressor regr = InsideForestRegressor(auto_feature_reduce=True, auto_fast=True, get_detail=True) regr.fit(X, y) Step 3: analyze results Inspect regr.df_clusters_description_ and regr.df_datos_explain_ for rules and metrics. Identify segments with high residuals for corrective actions. Save the model with regr.save(\"models/housing.joblib\"). Repeat the analysis with your data and compare with Performance Tips.",
    "excerpt": "Regression tutorial Model continuous values with InsideForest and explain each resulting region. Goal Predict diabetes progression using the classic Diabetes dataset included in scikit-learn. Step 1: load data from sklearn.datasets import l…"
  },
  {
    "title": "Persistencia de modelos",
    "url": "tutorials/persistence_es.html",
    "content": "Persistencia de modelos Guarda y reutiliza modelos InsideForest en producción. Guardar clf.save(\"artifacts/insideforest.joblib\") Cargar from InsideForest import InsideForestClassifier modelo = InsideForestClassifier.load(\"artifacts/insideforest.joblib\") etiquetas = modelo.predict(X_nuevo) Buenas prácticas Versiona archivos con fecha y número incremental. Adjunta catálogos derivados con MetaExtractor. Ejecuta pruebas automatizadas antes de desplegar. Amplía con la guía de reproducibilidad.",
    "excerpt": "Persistencia de modelos Guarda y reutiliza modelos InsideForest en producción. Guardar clf.save(\"artifacts/insideforest.joblib\") Cargar from InsideForest import InsideForestClassifier modelo = InsideForestClassifier.load(\"artifacts/insidefo…"
  },
  {
    "title": "Pipeline automation",
    "url": "tutorials/pipeline.html",
    "content": "Automate pipelines Integrate InsideForest into an automated flow with validation and persistence. Goal Create a reproducible pipeline that runs daily on new data. Step 1: organize the project mkdir -p pipelines cp templates/daily_pipeline.py pipelines/ Step 2: define the script # pipelines/daily_pipeline.py from InsideForest import InsideForestClassifier from insideforest.utils import load_data X_train, X_new, y_train = load_data() clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True) clf.fit(X_train, y_train) clf.save(\"artifacts/insideforest.joblib\") Step 3: validate in CI PYTHONPATH=src pytest tests/test_basic.py -q python pipelines/daily_pipeline.py Document the process following Reproducibility and share reports with Interpretation.",
    "excerpt": "Automate pipelines Integrate InsideForest into an automated flow with validation and persistence. Goal Create a reproducible pipeline that runs daily on new data. Step 1: organize the project mkdir -p pipelines cp templates/daily_pipeline.p…"
  },
  {
    "title": "Regresión",
    "url": "tutorials/regression_es.html",
    "content": "Tutorial de regresión Predice valores continuos y explica segmentos con InsideForest. Objetivo Modelar la progresión de la diabetes con el dataset clásico de scikit-learn. Paso 1: cargar datos from sklearn.datasets import load_diabetes X, y = load_diabetes(return_X_y=True) Paso 2: entrenar from InsideForest import InsideForestRegressor regr = InsideForestRegressor(auto_feature_reduce=True, auto_fast=True, get_detail=True) regr.fit(X, y) Paso 3: interpretar regr.df_clusters_description_ y regr.df_datos_explain_ para reglas y métricas. Localiza segmentos con error alto y genera acciones. Guarda el modelo con regr.save(\"modelos/housing.joblib\"). Consulta también Rendimiento para optimizar tiempos.",
    "excerpt": "Tutorial de regresión Predice valores continuos y explica segmentos con InsideForest. Objetivo Modelar la progresión de la diabetes con el dataset clásico de scikit-learn. Paso 1: cargar datos from sklearn.datasets import load_diabetes X, y…"
  },
  {
    "title": "Tutorials",
    "url": "tutorials/index.html",
    "content": "Tutorials Learn InsideForest step by step with guided notebooks and examples. Classification: build interpretable clusters for labeled classes. Regression: summarize continuous targets with rule-based regions. Pipelines: integrate InsideForest into scikit-learn workflows. Persistence: save, reload, and audit trained models. Download the notebooks from the repository tutorials/ directory and run them after completing the installation guide.",
    "excerpt": "Tutorials Learn InsideForest step by step with guided notebooks and examples. Classification: build interpretable clusters for labeled classes. Regression: summarize continuous targets with rule-based regions. Pipelines: integrate InsideFor…"
  },
  {
    "title": "Clasificación",
    "url": "tutorials/classification_es.html",
    "content": "Tutorial de clasificación Aprende a entrenar InsideForestClassifier con un dataset etiquetado. Objetivo Usar el conjunto Iris para generar segmentos interpretables. Paso 1: preparar datos from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split data = load_iris() X_train, X_test, y_train, y_test = train_test_split( data.data, data.target, train_size=0.35, stratify=data.target, random_state=15 ) Paso 2: entrenar y describir from InsideForest import InsideForestClassifier clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True, get_detail=True) clf.fit(X_train, y_train) segmentos = clf.df_clusters_description_ Paso 3: compartir resultados Extrae reglas clave desde segmentos o clf.df_datos_explain_. Visualiza importancias con clf.plot_importances(). Guarda el modelo con clf.save(\"modelos/iris.joblib\"). Sigue con el tutorial de regresión para el caso continuo.",
    "excerpt": "Tutorial de clasificación Aprende a entrenar InsideForestClassifier con un dataset etiquetado. Objetivo Usar el conjunto Iris para generar segmentos interpretables. Paso 1: preparar datos from sklearn.datasets import load_iris from sklearn.…"
  },
  {
    "title": "Classification",
    "url": "tutorials/classification.html",
    "content": "Classification tutorial Classify labeled observations and generate interpretable rules. Goal Train an InsideForestClassifier on the Iris dataset and produce a cluster report. Step 1: prepare the data from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split data = load_iris() X_train, X_test, y_train, y_test = train_test_split( data.data, data.target, train_size=0.35, stratify=data.target, random_state=15 ) Step 2: train and generate segments from InsideForest import InsideForestClassifier clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True, get_detail=True) clf.fit(X_train, y_train) segments = clf.df_clusters_description_ Step 3: interpret results Inspect segments or clf.df_datos_explain_ to review rules and metrics. Use clf.plot_importances() to visualize key variables. Export the model with clf.save(\"models/iris.joblib\"). Continue with the Regression tutorial to learn the continuous variant.",
    "excerpt": "Classification tutorial Classify labeled observations and generate interpretable rules. Goal Train an InsideForestClassifier on the Iris dataset and produce a cluster report. Step 1: prepare the data from sklearn.datasets import load_iris f…"
  },
  {
    "title": "Automatización de pipelines",
    "url": "tutorials/pipeline_es.html",
    "content": "Automatiza pipelines Integra InsideForest en un proceso repetible con pruebas y almacenamiento de artefactos. Objetivo Construir un pipeline diario que entrene, guarde el modelo y genere reportes. Paso 1: preparar estructura mkdir -p pipelines cp templates/daily_pipeline.py pipelines/ Paso 2: script principal from InsideForest import InsideForestClassifier from insideforest.utils import load_data X_train, X_new, y_train = load_data() clf = InsideForestClassifier(auto_fast=True, auto_feature_reduce=True) clf.fit(X_train, y_train) clf.save(\"artifacts/insideforest.joblib\") Paso 3: validar PYTHONPATH=src pytest tests/test_basic.py -q python pipelines/daily_pipeline.py Registra dependencias con Reproducibilidad y comunica resultados siguiendo la guía de Interpretación.",
    "excerpt": "Automatiza pipelines Integra InsideForest en un proceso repetible con pruebas y almacenamiento de artefactos. Objetivo Construir un pipeline diario que entrene, guarde el modelo y genere reportes. Paso 1: preparar estructura mkdir -p pipeli…"
  },
  {
    "title": "Tutoriales",
    "url": "tutorials/index_es.html",
    "content": "Tutoriales Ejemplos guiados para dominar InsideForest desde cero. Panorama general: flujo completo de trabajo. Segmentación de clientes: identifica segmentos minoristas. Scoring de riesgo: interpreta modelos de crédito. Encuentra los notebooks en el directorio tutorials/ del repositorio y configúralos siguiendo la instalación.",
    "excerpt": "Tutoriales Ejemplos guiados para dominar InsideForest desde cero. Panorama general: flujo completo de trabajo. Segmentación de clientes: identifica segmentos minoristas. Scoring de riesgo: interpreta modelos de crédito. Encuentra los notebo…"
  },
  {
    "title": "Model persistence",
    "url": "tutorials/persistence.html",
    "content": "Persist InsideForest models Learn how to save, version, and load models for production flows. Save models clf.save(\"artifacts/insideforest.joblib\") Load and reuse from InsideForest import InsideForestClassifier loaded = InsideForestClassifier.load(\"artifacts/insideforest.joblib\") labels = loaded.predict(X_new) Best practices Version artifacts with the date and model number. Store catalogs derived with MetaExtractor. Run pytest -q before promoting models. See Reproducibility for additional tips.",
    "excerpt": "Persist InsideForest models Learn how to save, version, and load models for production flows. Save models clf.save(\"artifacts/insideforest.joblib\") Load and reuse from InsideForest import InsideForestClassifier loaded = InsideForestClassifi…"
  },
  {
    "title": "Interpretación",
    "url": "guides/interpretation_es.html",
    "content": "Interpretación Transforma los resultados de InsideForest en historias accionables. Lista de verificación Resume número de clústeres, tamaño y métricas clave. Muestra reglas principales en tablas o bullets. Apoya con gráficos de plot_multi_dims o importancias. Relaciona hallazgos con decisiones: segmentos prioritarios, acciones recomendadas. Ejemplo El clúster 2 agrupa clientes con ticket alto y bajo churn; representa 14% de la base y merece campañas de fidelización. Exportación df_clusters_description_ para tablas (requiere get_detail=True al ajustar). generate_descriptions para textos automáticos. MetaExtractor para registrar parámetros desde tu catálogo. Complementa con la FAQ y los benchmarks para respaldar conclusiones.",
    "excerpt": "Interpretación Transforma los resultados de InsideForest en historias accionables. Lista de verificación Resume número de clústeres, tamaño y métricas clave. Muestra reglas principales en tablas o bullets. Apoya con gráficos de plot_multi_d…"
  },
  {
    "title": "Arquitectura",
    "url": "guides/architecture_es.html",
    "content": "Arquitectura InsideForest separa responsabilidades en capas para mantener los modelos interpretables y escalables. Capas Capa de bosque: manejada por Trees, compatible con scikit-learn y PySpark. Capa de regiones: Regions calcula métricas y genera rangos prioritarios. Capa de etiquetas: los auxiliares de cluster_selector y Labels consolidan y describen segmentos. Capa de utilidades: Models y MetaExtractor ofrecen auditoría y reportes. Flujo Entrena o conecta un bosque existente. Trees extrae reglas. Regions prioriza y estructura las regiones. Los auxiliares de cluster_selector consolidan según la estrategia deseada. Labels, Models y MetaExtractor generan reportes. Extensión Añade backends personalizados implementando la interfaz de Trees. Crea estrategias nuevas extendiendo los auxiliares de cluster_selector. Amplía reportes extendiendo Labels o creando utilidades sobre MetaExtractor. Sigue con Configuración para aprender a ajustar parámetros.",
    "excerpt": "Arquitectura InsideForest separa responsabilidades en capas para mantener los modelos interpretables y escalables. Capas Capa de bosque: manejada por Trees, compatible con scikit-learn y PySpark. Capa de regiones: Regions calcula métricas y…"
  },
  {
    "title": "Configuración",
    "url": "guides/configuration_es.html",
    "content": "Configuración Ajusta los parámetros de InsideForest según el tamaño de los datos y los objetivos del proyecto. Presets automáticos auto_fast: reduce profundidad y tamaño del bosque. auto_feature_reduce: selecciona variables relevantes. Parámetros manuales Parámetro Rol Consejo n_sample_multiplier Muestras por árbol. 0.05 para prototipos, 0.1–0.15 para análisis detallado. ef_sample_multiplier Muestreo exploratorio. Aumenta para datasets desbalanceados. method Consolidación de clústeres. menu maximiza precisión; select_clusters es más rápido. Entornos Local: crea un entorno virtual y ejecuta pytest -q. Servidor: registra parámetros con MetaExtractor y guarda modelos. PySpark: sincroniza spark.sql.shuffle.partitions con el tamaño de datos. Sigue con Interpretación para presentar resultados.",
    "excerpt": "Configuración Ajusta los parámetros de InsideForest según el tamaño de los datos y los objetivos del proyecto. Presets automáticos auto_fast: reduce profundidad y tamaño del bosque. auto_feature_reduce: selecciona variables relevantes. Pará…"
  },
  {
    "title": "Guides",
    "url": "guides/index.html",
    "content": "Guides Dive into core concepts and best practices for applying InsideForest to real projects. Architecture: internal structure and data flow. Configuration: parameters and automatic presets. Interpretation: how to communicate results. Pair these guides with the Quick API and tutorials to see practical examples.",
    "excerpt": "Guides Dive into core concepts and best practices for applying InsideForest to real projects. Architecture: internal structure and data flow. Configuration: parameters and automatic presets. Interpretation: how to communicate results. Pair …"
  },
  {
    "title": "Interpretation",
    "url": "guides/interpretation.html",
    "content": "Interpretation Translate InsideForest results into clear narratives for technical and business teams. Checklist Present an executive summary (number of clusters, key metrics). Show standout rules using tables or bullet points. Include visualizations created with plot_multi_dims or feature-importance charts. Connect findings to concrete actions (priority segments, target customers). Narrative example Cluster A groups young customers with high online spending; it represents 18% of the base and converts 1.4× above average. Exporting results df_clusters_description_: tables ready for Excel after calling fit(..., get_detail=True). generate_descriptions(...): produces short text snippets for reports. MetaExtractor: documents parameters used and feature masks from your catalog. Pair this guide with the FAQ and benchmarks to present quantitative evidence.",
    "excerpt": "Interpretation Translate InsideForest results into clear narratives for technical and business teams. Checklist Present an executive summary (number of clusters, key metrics). Show standout rules using tables or bullet points. Include visua…"
  },
  {
    "title": "Architecture",
    "url": "guides/architecture.html",
    "content": "Architecture InsideForest is organized into layers that separate rule extraction, region prioritization, and reporting. Main layers Forest layer: scikit-learn or PySpark forests managed by Trees. Region layer: Regions merges rules, computes metrics, and creates ranges. Label layer: Labels and the helpers in cluster_selector consolidate clusters. Utility layer: Models and MetaExtractor document outputs. Data flow The user trains or supplies a forest. Trees extracts rules and converts them into tabular structures. Regions computes metrics, prioritizes, and builds regions. cluster_selector helpers consolidate clusters based on the selected strategy. Labels, Models, and MetaExtractor produce final reports. Extensibility Add new backends by implementing the Trees interface. Define custom strategies by extending cluster_selector utilities. Extend reporting by adding helpers around Labels or MetaExtractor. Continue with Configuration to learn how to tune parameters and with the API reference for detailed module docs.",
    "excerpt": "Architecture InsideForest is organized into layers that separate rule extraction, region prioritization, and reporting. Main layers Forest layer: scikit-learn or PySpark forests managed by Trees. Region layer: Regions merges rules, computes…"
  },
  {
    "title": "Guías",
    "url": "guides/index_es.html",
    "content": "Guías Explora conceptos clave y recomendaciones para integrar InsideForest en tus flujos de trabajo. Arquitectura: componentes internos y flujo de datos. Configuración: parámetros y presets. Interpretación: comunicación de resultados. Apóyate también en la API rápida y los tutoriales.",
    "excerpt": "Guías Explora conceptos clave y recomendaciones para integrar InsideForest en tus flujos de trabajo. Arquitectura: componentes internos y flujo de datos. Configuración: parámetros y presets. Interpretación: comunicación de resultados. Apóya…"
  },
  {
    "title": "Configuration",
    "url": "guides/configuration.html",
    "content": "Configuration Adjust InsideForest for different dataset sizes and business goals. Automatic presets auto_fast: limits forest depth and size for quicker exploration. auto_feature_reduce: removes redundant variables before clustering. Manual parameters Parameter Role Recommendation n_sample_multiplier Samples per tree. Use 0.05 for quick tests, up to 0.15 for more detail. ef_sample_multiplier Exploratory sampling. Increase to 15 for imbalanced datasets. method Cluster consolidation. menu for precision, select_clusters for speed. Execution environments Local: use venv or conda and run pytest -q. Server: enable logging and persistence with .save(). PySpark: adjust partitions with spark.sql.shuffle.partitions. Continue with Interpretation to learn how to present results.",
    "excerpt": "Configuration Adjust InsideForest for different dataset sizes and business goals. Automatic presets auto_fast: limits forest depth and size for quicker exploration. auto_feature_reduce: removes redundant variables before clustering. Manual …"
  },
  {
    "title": "Auxiliares de selección",
    "url": "api/clusterselector_es.html",
    "content": "Auxiliares de selección El módulo InsideForest.cluster_selector ofrece funciones y clases para equilibrar o consolidar los clústeres generados por Regions.labels. Ya no existe una clase única ClusterSelector; emplea los auxiliares específicos según la necesidad. Herramientas destacadas balance_lists_n_clusters(df_reres, seed=None): consolida etiquetas buscando tamaños similares. max_prob_clusters(df_reres): asigna el clúster con mayor probabilidad para cada registro. match_class_distribution(df_reres, y): ajusta asignaciones para respetar la distribución original de clases. MenuClusterSelector(quota=0.0, seed=None): aprende un menú de candidatos y selecciona la mejor configuración con métricas de información. ChimeraValuesSelector(quota=0.0, seed=None): combina siluetas y cuotas para suavizar asignaciones. Ejemplo from InsideForest import cluster_selector # Tras ejecutar InsideForestClassifier(..., get_detail=True).fit(X, y) menu = cluster_selector.MenuClusterSelector(quota=0.2) menu.fit(clf.df_reres_, y) resultado = menu.predict(clf.df_reres_) # También puedes usar una función directa balanceado = cluster_selector.balance_lists_n_clusters(clf.df_reres_, seed=42) Todos los auxiliares operan sobre el DataFrame que devuelve Regions.prio_ranges, disponible como df_reres_ en los envoltorios de alto nivel cuando se activa get_detail=True.",
    "excerpt": "Auxiliares de selección El módulo InsideForest.cluster_selector ofrece funciones y clases para equilibrar o consolidar los clústeres generados por Regions.labels. Ya no existe una clase única ClusterSelector; emplea los auxiliares específic…"
  },
  {
    "title": "InsideForestClassifier",
    "url": "api/insideforestclassifier_es.html",
    "content": "InsideForestClassifier Clase de alto nivel para entrenar un bosque supervisado, generar regiones y obtener etiquetas interpretables en tareas de clasificación. Firma InsideForestClassifier( rf_params=None, tree_params=None, auto_fast=False, auto_feature_reduce=False, method=\"select_clusters\", balance_clusters=False, get_detail=False, divide=5, random_state=None, ) Parámetros destacados Parámetro Descripción rf_params Parámetros para el bosque base de scikit-learn. tree_params Controla la extracción de reglas (por ejemplo n_sample_multiplier). auto_fast Activa presets de velocidad y reducción de muestreo. method Estrategia de consolidación (select_clusters, menu, etc.). balance_clusters Equilibra la contribución por clase en los clústeres finales. Flujo recomendado clf = InsideForestClassifier( auto_fast=True, auto_feature_reduce=True, method=\"menu\", get_detail=True, rf_params={\"random_state\": 21, \"n_estimators\": 400}, ) clf.fit(X_train, y_train) etiquetas = clf.predict(X_test) resumen = clf.df_clusters_description_ clf.save(\"modelos/insideforest_clf.joblib\") Atributos útiles feature_importances_: importancia de variables. feature_names_out_: nombres tras reducción automática. df_clusters_description_ y df_datos_explain_: disponibles cuando activas get_detail=True. df_reres_: reglas priorizadas almacenadas tras el ajuste. _fast_params_used_: presets aplicados. Recursos relacionados InsideForestRegressor Trees para personalización avanzada. Auxiliares de selección para estrategias de equilibrio. API rápida con ejemplos completos.",
    "excerpt": "InsideForestClassifier Clase de alto nivel para entrenar un bosque supervisado, generar regiones y obtener etiquetas interpretables en tareas de clasificación. Firma InsideForestClassifier( rf_params=None, tree_params=None, auto_fast=False,…"
  },
  {
    "title": "Regions",
    "url": "api/regions_es.html",
    "content": "Regions Prioriza y combina las ramas generadas por Trees para formar regiones consistentes que luego serán etiquetadas. Funciones principales prio_ranges(branches, X, y=None): calcula cobertura, pureza y prioridad. labels(X, ranges, return_descriptions=False): asigna etiquetas y descripciones. plot_multi_dims(range_df, data, target): visualiza regiones en 2D/3D. Ejemplo regions = Regions() rangos = regions.prio_ranges(branches, X) clusteres, descripciones = regions.labels(X, rangos, True) Parámetros min_support: tamaño mínimo de región. max_rules: número máximo de reglas por clúster. use_probabilities: pondera cada región según la probabilidad del bosque. Su salida alimenta a Labels y a los envoltorios de alto nivel. Complementa con consejos de rendimiento.",
    "excerpt": "Regions Prioriza y combina las ramas generadas por Trees para formar regiones consistentes que luego serán etiquetadas. Funciones principales prio_ranges(branches, X, y=None): calcula cobertura, pureza y prioridad. labels(X, ranges, return_…"
  },
  {
    "title": "InsideForestRegressor",
    "url": "api/insideforestregressor_es.html",
    "content": "InsideForestRegressor Envoltorio para tareas de regresión que combina bosques, extracción de regiones y reglas interpretables. Firma InsideForestRegressor( rf_params=None, tree_params=None, auto_fast=False, auto_feature_reduce=False, method=\"select_clusters\", get_detail=False, divide=5, random_state=None, ) Uso básico regr = InsideForestRegressor( auto_feature_reduce=True, auto_fast=True, get_detail=True, rf_params={\"random_state\": 42, \"n_estimators\": 500}, ) regr.fit(X_train, y_train) predicciones = regr.predict(X_test) segmentos = regr.df_clusters_description_ Cuándo utilizarlo Necesitas explicar segmentos por valor numérico (ingresos, riesgo, precio). Requieres reglas legibles para auditorías o cumplimiento. Buscas reducción automática de características antes de generar reglas. Atributos feature_importances_ feature_names_out_ df_clusters_description_ y df_datos_explain_ (con get_detail=True) df_reres_ Complementa con los auxiliares de selección y las utilidades de metadatos para auditoría.",
    "excerpt": "InsideForestRegressor Envoltorio para tareas de regresión que combina bosques, extracción de regiones y reglas interpretables. Firma InsideForestRegressor( rf_params=None, tree_params=None, auto_fast=False, auto_feature_reduce=False, method…"
  },
  {
    "title": "Metadata",
    "url": "api/metadata_es.html",
    "content": "Utilidades de metadatos El módulo InsideForest.metadata conecta las descripciones de clúster con el catálogo de datos de tu organización para auditar recomendaciones y planear experimentos. Herramientas principales MetaExtractor: vincula los tokens presentes en cluster_description con filas del catálogo y limita las columnas según el perfil seleccionado en Profile. parse_rule_string, token_from_condition y conditions_to_tokens: dividen reglas en condiciones individuales y tokens reutilizables. experiments_from_df2 y run_experiments: generan hipótesis contrastando clústeres y priorizan dónde intervenir. Ejemplo import pandas as pd from InsideForest import MetaExtractor, Profile, run_experiments metadata_df = tabla_perfil.set_index(\"variable_id\") # incluye la fila de la variable objetivo mx = MetaExtractor(metadata_df, var_obj=\"target\") catalogo = mx.extract( clf.df_clusters_description_, profile=Profile.BUSINESS, ) registros = df_entrenamiento.copy() registros[\"target\"] = y hipotesis = run_experiments( mx, {\"iris\": clf.df_clusters_description_}, data_dict={\"iris\": registros}, ) Nota: el catálogo de metadatos debe estar indexado por los tokens presentes en cluster_description y contener la fila de la variable objetivo. Las tablas detalladas df_clusters_description_ y df_datos_explain_ se generan cuando ajustas el estimador con get_detail=True. Combina estos reportes con los activos de la guía de Reproducibilidad.",
    "excerpt": "Utilidades de metadatos El módulo InsideForest.metadata conecta las descripciones de clúster con el catálogo de datos de tu organización para auditar recomendaciones y planear experimentos. Herramientas principales MetaExtractor: vincula lo…"
  },
  {
    "title": "InsideForestRegressor",
    "url": "api/insideforestregressor.html",
    "content": "InsideForestRegressor Regression-oriented variant that uses forests to discover regions with similar numeric values and interpretable rules. Signature InsideForestRegressor( rf_params=None, tree_params=None, auto_fast=False, auto_feature_reduce=False, method=\"select_clusters\", get_detail=False, divide=5, random_state=None, ) Usage from InsideForest import InsideForestRegressor regr = InsideForestRegressor( auto_feature_reduce=True, auto_fast=True, get_detail=True, rf_params={\"random_state\": 42, \"n_estimators\": 500}, ) regr.fit(X_train, y_train) predictions = regr.predict(X_test) clusters = regr.df_clusters_description_ When to use You need to explain customer segments by spending, income, or risk levels. You want human-readable rules for pricing or forecasting audits. You aim to reduce dimensionality automatically before grouping. Attributes feature_importances_ feature_names_out_ df_clusters_description_ and df_datos_explain_ (with get_detail=True) df_reres_ For advanced options see cluster selector helpers and the metadata helpers.",
    "excerpt": "InsideForestRegressor Regression-oriented variant that uses forests to discover regions with similar numeric values and interpretable rules. Signature InsideForestRegressor( rf_params=None, tree_params=None, auto_fast=False, auto_feature_re…"
  },
  {
    "title": "Models",
    "url": "api/models.html",
    "content": "Models Utilities to evaluate and compare models associated with InsideForest. Key functions compare_models(models, X, y): compare metrics across different base models. plot_importances(model, top_n=20): visualize cumulative importances. confusion_matrix(labels, y): generate confusion matrices for clusters. Example from InsideForest import Models models = Models() summary = models.compare_models([ (\"baseline_rf\", baseline_rf), (\"insideforest\", clf.model_), ], X_test, y_test) Use these outputs alongside the metadata helpers and the reports from Labels.",
    "excerpt": "Models Utilities to evaluate and compare models associated with InsideForest. Key functions compare_models(models, X, y): compare metrics across different base models. plot_importances(model, top_n=20): visualize cumulative importances. con…"
  },
  {
    "title": "Labels",
    "url": "api/labels.html",
    "content": "Labels Generates reports, metrics, and descriptions for the regions produced by Regions. Functions generate_descriptions(region_df, feature_names): produces short text per cluster. categorize_conditions(descriptions): groups conditions by type. summaries(clusterized): coverage, purity, and size metrics. Example from InsideForest import Labels labels = Labels() summary = labels.summaries(clusterized) descriptions = labels.generate_descriptions(descriptive, feature_names) These reports can be exported to CSV or Markdown and complement the df_clusters_description_ and df_datos_explain_ attributes exposed by the high-level wrappers.",
    "excerpt": "Labels Generates reports, metrics, and descriptions for the regions produced by Regions. Functions generate_descriptions(region_df, feature_names): produces short text per cluster. categorize_conditions(descriptions): groups conditions by t…"
  },
  {
    "title": "Regions",
    "url": "api/regions.html",
    "content": "Regions Combines the branches extracted by Trees and prioritizes those that form consistent clusters. Main functions prio_ranges(branches, X, y=None): computes coverage, purity, and priority metrics. labels(X, ranges, return_descriptions=False): assigns labels and optionally generates descriptions. plot_multi_dims(range_df, data, target): visualizes regions across multiple dimensions. Usage from InsideForest import Regions regions = Regions() priority_ranges = regions.prio_ranges(branches, X) clusterized, descriptions = regions.labels(X, priority_ranges, True) Relevant parameters min_support: minimum region size to be considered. max_rules: maximum number of rules per cluster. use_probabilities: weights by forest probabilities. The output of labels feeds into Labels and the methods in InsideForestClassifier.",
    "excerpt": "Regions Combines the branches extracted by Trees and prioritizes those that form consistent clusters. Main functions prio_ranges(branches, X, y=None): computes coverage, purity, and priority metrics. labels(X, ranges, return_descriptions=Fa…"
  },
  {
    "title": "Trees",
    "url": "api/trees_es.html",
    "content": "Trees Extrae las ramas de un bosque entrenado para que puedan priorizarse y etiquetarse. Compatible con modelos de scikit-learn y PySpark. Firma Trees( backend=\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10, max_depth=None, ) Funciones principales get_branches(X, y, model=None): retorna las ramas; entrena un bosque si no se proporciona. plot_importances(model): visualiza importancias de características. Parámetros clave backend: selecciona \"sklearn\" o \"pyspark\". n_sample_multiplier: porcentaje de muestras por árbol. ef_sample_multiplier: factor para muestreo exploratorio. max_depth: profundidad máxima al extraer reglas. Los resultados alimentan a Regions y Labels. Revisa Rendimiento para recomendaciones adicionales.",
    "excerpt": "Trees Extrae las ramas de un bosque entrenado para que puedan priorizarse y etiquetarse. Compatible con modelos de scikit-learn y PySpark. Firma Trees( backend=\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10, max_depth=None, ) …"
  },
  {
    "title": "Labels",
    "url": "api/labels_es.html",
    "content": "Labels Convierte las regiones priorizadas en reportes y métricas listos para compartir. Funciones generate_descriptions(region_df, feature_names): textos descriptivos por clúster. categorize_conditions(descriptions): agrupa condiciones por tipo. summaries(clusterized): métricas de cobertura y pureza. Ejemplo labels = Labels() resumen = labels.summaries(clusteres) descripciones = labels.generate_descriptions(descriptivo, feature_names) Integra estos resultados en dashboards o reportes y combínalos con los atributos df_clusters_description_ y df_datos_explain_ (disponibles en los envoltorios cuando activas get_detail=True). Consulta también reproducibilidad para documentar versiones.",
    "excerpt": "Labels Convierte las regiones priorizadas en reportes y métricas listos para compartir. Funciones generate_descriptions(region_df, feature_names): textos descriptivos por clúster. categorize_conditions(descriptions): agrupa condiciones por …"
  },
  {
    "title": "InsideForestClassifier",
    "url": "api/insideforestclassifier.html",
    "content": "InsideForestClassifier High-level wrapper that trains a supervised forest, extracts regions, and generates interpretable labels for classification tasks. Signature InsideForestClassifier( rf_params=None, tree_params=None, auto_fast=False, auto_feature_reduce=False, method=\"select_clusters\", balance_clusters=False, get_detail=False, divide=5, random_state=None, ) Key parameters Parameter Description rf_params Dictionary with parameters for the underlying RandomForest model. tree_params Configures rule extraction (for example n_sample_multiplier). auto_fast Applies automatic presets to speed up training and extraction. method Strategy to consolidate clusters (select_clusters, menu, etc.). balance_clusters Balances the contribution of each class during consolidation. Workflow from InsideForest import InsideForestClassifier clf = InsideForestClassifier( auto_fast=True, auto_feature_reduce=True, method=\"menu\", get_detail=True, rf_params={\"random_state\": 21, \"n_estimators\": 400}, ) clf.fit(X_train, y_train) pred_labels = clf.predict(X_test) report = clf.df_clusters_description_ clf.save(\"models/insideforest_clf.joblib\") Attributes feature_importances_: feature importance scores from the base forest. feature_names_out_: feature names after automatic reduction. df_clusters_description_ and df_datos_explain_: populated when get_detail=True. df_reres_: cached regions returned by Regions.prio_ranges. _fast_params_used_: summary of applied presets. See also InsideForestRegressor Trees to customize rule extraction. Cluster selector helpers for advanced consolidation strategies. Quick API for complete examples.",
    "excerpt": "InsideForestClassifier High-level wrapper that trains a supervised forest, extracts regions, and generates interpretable labels for classification tasks. Signature InsideForestClassifier( rf_params=None, tree_params=None, auto_fast=False, a…"
  },
  {
    "title": "API Reference",
    "url": "api/index.html",
    "content": "API Reference The InsideForest API is organized into modules that cover rule extraction, region prioritization, labeling, and supporting utilities. Use this page as a map to navigate each component. High-level wrappers InsideForestClassifier InsideForestRegressor Core components Trees: extract branches from forests. Regions: prioritize and consolidate regions. Labels: metrics, reporting, and export helpers. Cluster selector helpers: strategies to balance clusters. Utilities Models: evaluate and compare models. Metadata helpers: connect rules with your data catalog. To understand the full pipeline, also review How It Works and the Quick API. Every page includes a Spanish version through the language selector.",
    "excerpt": "API Reference The InsideForest API is organized into modules that cover rule extraction, region prioritization, labeling, and supporting utilities. Use this page as a map to navigate each component. High-level wrappers InsideForestClassifie…"
  },
  {
    "title": "Trees",
    "url": "api/trees.html",
    "content": "Trees The Trees module extracts branches and rules from a trained forest. It supports scikit-learn and PySpark models. Signature Trees( backend=\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10, max_depth=None, ) Main functions get_branches(X, y, model=None): returns the forest branches. When model is not provided, the forest is trained internally. plot_importances(model): generates an importance plot for quick diagnostics. Typical usage from InsideForest import Trees trees = Trees(\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10) branches = trees.get_branches(X, y, fitted_model) Key parameters backend: \"sklearn\" or \"pyspark\" depending on the forest type. n_sample_multiplier: controls the sample used to evaluate rules. ef_sample_multiplier: adjusts exploratory sampling to discover additional regions. max_depth: limits depth while extracting rules. The output feeds into Regions and Labels. See Performance Tips for parameter guidance.",
    "excerpt": "Trees The Trees module extracts branches and rules from a trained forest. It supports scikit-learn and PySpark models. Signature Trees( backend=\"sklearn\", n_sample_multiplier=0.05, ef_sample_multiplier=10, max_depth=None, ) Main functions g…"
  },
  {
    "title": "Referencia API",
    "url": "api/index_es.html",
    "content": "Referencia de la API Usa esta página para navegar rápidamente los módulos principales de InsideForest. Cada enlace ofrece ejemplos, parámetros y notas de uso. Envoltorios principales InsideForestClassifier InsideForestRegressor Componentes base Trees: extracción de reglas a partir de bosques. Regions: priorización y combinación de regiones. Labels: generación de reportes e interpretaciones. Auxiliares de selección: estrategias de consolidación. Utilidades complementarias Models: métricas y comparación de modelos. Utilidades de metadatos: enlaza reglas con tu catálogo de datos. Para entender el contexto completo, revisa cómo funciona InsideForest y los ejemplos de la API rápida.",
    "excerpt": "Referencia de la API Usa esta página para navegar rápidamente los módulos principales de InsideForest. Cada enlace ofrece ejemplos, parámetros y notas de uso. Envoltorios principales InsideForestClassifier InsideForestRegressor Componentes …"
  },
  {
    "title": "Cluster selector helpers",
    "url": "api/clusterselector.html",
    "content": "Cluster selector helpers The InsideForest.cluster_selector module exposes utilities that rebalance or consolidate clusters produced by Regions.labels. Instead of a single ClusterSelector class, use the dedicated functions and classes described below. Key utilities balance_lists_n_clusters(df_reres, seed=None): returns consolidated labels after enforcing similar cluster sizes. max_prob_clusters(df_reres): favors the clusters with highest probability per record. match_class_distribution(df_reres, y): adjusts assignments to mirror the original class distribution. MenuClusterSelector(quota=0.0, seed=None): fits a menu of candidate clusters and selects the best configuration according to information-theoretic scores. ChimeraValuesSelector(quota=0.0, seed=None): combines silhouettes and quota enforcement to smooth assignments. Example from InsideForest import cluster_selector # After calling InsideForestClassifier(..., get_detail=True).fit(X, y) menu = cluster_selector.MenuClusterSelector(quota=0.2) menu.fit(clf.df_reres_, y) rebalanced = menu.predict(clf.df_reres_) # Alternatively apply a functional helper balanced = cluster_selector.balance_lists_n_clusters(clf.df_reres_, seed=42) All helpers operate on the DataFrame returned by Regions.prio_ranges, which is stored as df_reres_ inside the high-level wrappers when get_detail=True.",
    "excerpt": "Cluster selector helpers The InsideForest.cluster_selector module exposes utilities that rebalance or consolidate clusters produced by Regions.labels. Instead of a single ClusterSelector class, use the dedicated functions and classes descri…"
  },
  {
    "title": "Metadata",
    "url": "api/metadata.html",
    "content": "Metadata helpers The InsideForest.metadata module bridges cluster descriptions with your organization’s data catalog so you can audit recommendations and design follow-up experiments. Main utilities MetaExtractor: maps the tokens found in cluster_description to rows in a metadata catalog and filters the columns to keep via the Profile enum. parse_rule_string, token_from_condition and conditions_to_tokens: helpers that split rule text into individual conditions and reusable tokens. experiments_from_df2 and run_experiments: generate contrastive hypotheses between clusters, ranking where to intervene first. Example import pandas as pd from InsideForest import MetaExtractor, Profile, run_experiments metadata_df = profiler_table.set_index(\"variable_id\") # must include the target row mx = MetaExtractor(metadata_df, var_obj=\"target\") catalog = mx.extract( clf.df_clusters_description_, profile=Profile.INVESTIGATION, ) records = training_df.copy() records[\"target\"] = y hypotheses = run_experiments( mx, {\"iris\": clf.df_clusters_description_}, data_dict={\"iris\": records}, ) Note: the metadata catalog must be indexed by the variable tokens found in cluster_description plus the target column. The detailed DataFrames df_clusters_description_ and df_datos_explain_ are populated when the estimator is fitted with get_detail=True. Combine the extracted catalog with reproducibility assets from the Reproducibility guide.",
    "excerpt": "Metadata helpers The InsideForest.metadata module bridges cluster descriptions with your organization’s data catalog so you can audit recommendations and design follow-up experiments. Main utilities MetaExtractor: maps the tokens found in c…"
  },
  {
    "title": "Models",
    "url": "api/models_es.html",
    "content": "Models Herramientas para comparar modelos base, visualizar importancias y analizar desempeño. Funciones compare_models(models, X, y): compara métricas entre modelos. plot_importances(model, top_n=20): grafica importancias. confusion_matrix(labels, y): matriz de confusión para clústeres. Ejemplo models = Models() reporte = models.compare_models([ (\"baseline_rf\", baseline_rf), (\"insideforest\", clf.model_), ], X_test, y_test) Usa estos resultados junto con las utilidades de metadatos y Labels para preparar reportes completos.",
    "excerpt": "Models Herramientas para comparar modelos base, visualizar importancias y analizar desempeño. Funciones compare_models(models, X, y): compara métricas entre modelos. plot_importances(model, top_n=20): grafica importancias. confusion_matrix(…"
  }
]