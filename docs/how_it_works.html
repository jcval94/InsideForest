---
layout: default
title: How It Works
description: Explanation of InsideForest's supervised clustering approach.
parent: InsideForest
nav_order: 4
---

<h1>How InsideForest Works</h1>
<p>InsideForest takes a trained decision forest and turns it into interpretable regions. The full pipeline follows four stages: trees → rules → regions → labels.</p>

<h2>1. Build or reuse a forest</h2>
<p>You can train a <code>RandomForest</code> directly or provide a pre-trained forest from PySpark. The <code>InsideForestClassifier</code> and <code>InsideForestRegressor</code> wrappers accept common <code>scikit-learn</code> parameters, or you can use the <code>Trees</code> class to extract branches manually.</p>
<pre><code class="language-python">from InsideForest import Trees

trees = Trees("sklearn", n_sample_multiplier=0.05, ef_sample_multiplier=10)
branches = trees.get_branches(X, y, fitted_model)
</code></pre>

<h2>2. Prioritize candidate regions</h2>
<p><code>Regions.prio_ranges</code> combines the rules from every tree, computes coverage metrics, and highlights regions that balance purity and size.</p>
<pre><code class="language-python">from InsideForest import Regions

regions = Regions()
priority_ranges = regions.prio_ranges(branches, X)
</code></pre>
<p>This stage can also reduce features when <code>auto_feature_reduce=True</code>, keeping only the most discriminative variables.</p>

<h2>3. Label observations</h2>
<p>The prioritized regions are used to label new or existing observations. The <code>regions.labels</code> function assigns rules, calculates metrics, and—when <code>return_dfs=True</code>—returns detailed DataFrames.</p>
<pre><code class="language-python">df = X.copy()
df["target"] = y
clustered, descriptive, labels = regions.labels(
    df=df,
    df_reres=priority_ranges,
    n_clusters=None,
    include_summary_cluster=False,
    method="select_clusters",
    return_dfs=True,
    var_obj="target",
)
</code></pre>
<p>Labels can be consolidated with strategies such as <code>select_clusters</code>, <code>menu</code>, or <code>match_class_distribution</code> using the helpers from <code>InsideForest.cluster_selector</code>.</p>

<h2>4. Interpret and export</h2>
<p>The <a href="api/labels.html">Labels</a> module summarizes metrics per cluster, while <a href="api/models.html">Models</a> offers tools to compare baselines and export rules.</p>
<ul>
  <li><code>generate_descriptions</code> produces short narratives for analysts.</li>
  <li><code>categorize_conditions</code> groups rules by constraint type.</li>
  <li><code>plot_multi_dims</code> visualizes regions in 2D or 3D.</li>
</ul>

<h2>Putting it together</h2>
<p>The snippet below illustrates the full flow using the high-level wrappers:</p>
<pre><code class="language-python">from InsideForest import InsideForestClassifier

clf = InsideForestClassifier(
    auto_fast=True,
    auto_feature_reduce=True,
    method="menu",
    get_detail=True,
)
clf.fit(X_train, y_train)
labels = clf.predict(X_test)
descriptions = clf.df_clusters_description_
</code></pre>

<h2>Learn more</h2>
<ul>
  <li><a href="performance_tips.html">Performance Tips</a> to fine-tune parameters.</li>
  <li><a href="experiments_benchmarks.html">Experiments &amp; Benchmarks</a> to review quantitative results.</li>
  <li><a href="reproducibility.html">Reproducibility</a> to guarantee reliable experiments.</li>
</ul>
